{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77aa5d1",
   "metadata": {},
   "source": [
    "***RAG***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5b24e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in d:\\anaconda3\\lib\\site-packages (0.3.29)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: langchain_OpenAI in d:\\anaconda3\\lib\\site-packages (0.3.32)\n",
      "Requirement already satisfied: langchainhub in d:\\anaconda3\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: Chromadb in d:\\anaconda3\\lib\\site-packages (1.0.20)\n",
      "Requirement already satisfied: langchain in d:\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (0.3.75)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (3.11.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (0.4.20)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in d:\\anaconda3\\lib\\site-packages (from langchain_community) (2.1.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in d:\\anaconda3\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\anaconda3\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in d:\\anaconda3\\lib\\site-packages (from langchain_OpenAI) (1.102.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\anaconda3\\lib\\site-packages (from langchain_OpenAI) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain_OpenAI) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain_OpenAI) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain_OpenAI) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain_OpenAI) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain_OpenAI) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain_OpenAI) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_OpenAI) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_OpenAI) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_OpenAI) (2024.11.6)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in d:\\anaconda3\\lib\\site-packages (from langchainhub) (2.32.4.20250809)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->Chromadb) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (1.36.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (0.22.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\anaconda3\\lib\\site-packages (from Chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (3.11.3)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in d:\\anaconda3\\lib\\site-packages (from Chromadb) (4.23.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->Chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in d:\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->Chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->Chromadb) (2.2.1)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\anaconda3\\lib\\site-packages (from build>=1.0.3->Chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from build>=1.0.3->Chromadb) (0.4.6)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->Chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->Chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->Chromadb) (0.22.3)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->Chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->Chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->Chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in d:\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->Chromadb) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in d:\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->Chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->Chromadb) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->Chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->Chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->Chromadb) (0.4.8)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in d:\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->Chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->Chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in d:\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->Chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in d:\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->Chromadb) (1.13.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in d:\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->Chromadb) (8.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->Chromadb) (3.21.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in d:\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->Chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in d:\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->Chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in d:\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->Chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in d:\\anaconda3\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->Chromadb) (0.57b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda3\\lib\\site-packages (from rich>=10.11.0->Chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda3\\lib\\site-packages (from rich>=10.11.0->Chromadb) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->Chromadb) (0.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\anaconda3\\lib\\site-packages (from tokenizers>=0.13.2->Chromadb) (0.34.4)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->Chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->Chromadb) (2025.3.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda3\\lib\\site-packages (from typer>=0.9.0->Chromadb) (8.1.8)\n",
      "Requirement already satisfied: httptools>=0.6.3 in d:\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->Chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->Chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->Chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->Chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in d:\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->Chromadb) (3.5.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->Chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community langchain_OpenAI langchainhub Chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb678de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hands-on Generative AI CourseCoursesBundle CoursesMentorFree ContentTestimonialsFAQLogin Signup Starts on 16th September 2025Hands-on Generative AI CourseLearn, Build, Deploy and Apply Generative AI7 weeks · 3 classes/week · 2 hrs/class + Post-class Doubt SupportClasses on Tue, Wed, Thurs - 9PM ISTAccess all Live BatchesLifetime access of RecordingsAccess Discord CommunityCode availableBuild ProjectsLearn Future-Ready TechEnroll 1Week 1Foundations of Generative AI Introduction to AI Mathematical Foundations for AI Probability, Statistics, and Linear Algebra Basics of Neural Networks Gradient Descent and Optimization Basics Architectures: Feedforward, RNN, and CNN Mini Project - Build a Simple Neural Network Using TensorFlow Mini Project - Train an Autoencoder on the MNIST Dataset2Week 2Deep Generative Models Discriminative and Generative models Generative Adversarial Networks (GANs) Variational Autoencoders (VAEs) Probabilistic Data Generation Using VAEs Four Mini Projects using TensorFlow Metrics Visualization using TensorBoard Mini Project - Implement a GAN to Generate Handwritten Digits Mini Project - Train a VAE to Generate Faces Using the CelebA Dataset3Week 3Transformers and Large Language Models RNN, LSTM Transformers Architecture Attention Mechanism: Self-Attention and Positional Encoding Major Project - Code Transformer from scratch Encoder-Decoder Framework Pretraining objectives: MLM, CLM GPT, BERT Mini Project - Sentiment Analysis Using BERT4Week 4Fine-Tuning, LangChain, LangGraph Pretraining and Fine-Tuning LoRA, QLoRA Hugging Face Fine-tuning for Tasks Like Summarization, QA LangChain Installation and Basic Setup Overview of LangChain: Prompts, Memory, Chains, Agents LangGraph: Nodes, State, StateGraph, Workflows AI Agents Mini Project - Simple Q&A Application Using LangChain5Week 5Vector Databases, RAG Vector Databases ChromaDB Applications of RAG Building RAG Pipelines with LangChain Building Frontend using Streamlit Major Project - Build End to End Chatbot like ChatGPT using Streamlit, LangGraph, ChromaDB, WebSearch Tools, Memory with LLMs Project - Build an App using Streamlit for Image Generation, Image Caption Generation, Video Caption Generation6Week 6Trending Topics MCP - Model Context Protocol Ollama Projects - Fine-Tuning using Unsloth Mixture of Experts Chain of Thoughts Deepseek Architecture7Week 7Projects, Trending Topics Distillation Diffusion Models Vision Transformers Multimodal Models CLIP Prompt EngineeringTestimonialsWe've a large community of talentsVoices of Delight: Discover what our students say about their learning journey. Real stories, real satisfaction—explore testimonials that reflect the quality, dedication, and excellence we strive to deliver.Sahitya Raj ACo-founderSreeal TechnologiesI attended Educosys live Generative AI online course, and despite not being a beginner in the field, I found it incredibly valuable for learners at all levels. The curriculum was well-structured, covering everything from basic neural networks to advanced frameworks and architectures.  One of the highlights was the transformer architecture, which was covered in remarkable depth with absolute clarity—no confusion, just a seamless understanding of self-attention, positional encoding, and how these models scale. And the way Keerti delivered it leaves a lasting impact—truly unmatched and unforgettable! Beyond the structured content, they also stretched beyond to cover the absolute latest - DeepSeek. Concepts that once felt intimidating now feel second nature.  An added bonus was the notes, which removed the overhead of excessive note-taking and allowed for more focused learning. The balance between theory and hands-on learning was perfect, making it easy to apply new knowledge in real-world projects. By the end of the course, I feel a significant boost in my confidence—whether at work, workshops, meetups, discussions, projects, or analyzing cutting-edge AI advancements.  This course is truly for everyone, whether you’re getting started or deepening your expertise in Generative AI. Highly recommended! Kudos to Keerthi and Amit for their incredible efforts in designing and delivering this course so beautifully, and for the vast amount of knowledge they have gathered and shared with us!Read moreAshish UpretiLead SDEIntelI really enjoyed the GenAI course. Coming from someone with zero knowledge on the topic, after seven weeks, I'm able to understand the magic behind GenAI. I also liked the quality of the content and how you broke down such a complex topic for easy understanding. I appreciate your patience and eagerness to clarify all the doubts. I have already enrolled in the LLD and HLD courses and am looking forward to it.Read moreSathish KrishnaBusiness Enterprise ArchitectIBMGenerative AI has been so much helpful for me in my job and my research, that this course has given me a breadth and depth of the fundamentals of every topic that we have been hearing in the trends of Computing Domain. Keerti has thought this course in a wonderful way that I can slice and dice the complexity to understand the reasoning behind each concept. I recommend this course to everyone. Kudos to Keerti and her entire team.Read moreRaman SharmaPrincipal Software EngineerOracleI found the course very helpful and well structured. It started with the very basics of neural networks, it even touched upon the maths to get a proper understanding of what's going on under the hood. Gradually progressing towards more advanced models like CNN, RNN, and then transformers was done in a steady and helpful way. The intuitions Keerti provided were very useful and make a lasting impression in your mind regarding the topic. I haven't found such intuitions and easy to understand explanations elsewhere. Taking this course has increased my confidence towards GenAI and it has given me a solid platform from where I can read more AI related blogs, whitepapers, etc. without feeling overwhelmed. It has even helped me demonstrate a POC within my team that was well received. I recommend this course to anyone starting out with GenAIRead moreSudarshan Suresh SrikantSoftware EngineerCienaKudos to the Educosys team and thanks to Keerti for making learning AI/ML easy. Starting from the basics upto advanced level with most up to date AI developments, the course instilled me with great confidence in approaching problems that could be solved with AI. Every minute detail with code was covered in-depth. I would definitely recommend taking up this course.Read moreSyed IInformation Security OfficerForm3A real game changer of a course especially when it comes to real world applications. Keerti is an amazing mentor and gets to the crux of the learning without any frills. Highly recommend.Ruthira SekarI'm Database developer/DBA, Completing the Generative AI course was an insightful experience, deepening my knowledge of Machine Learning. Keerti’s passion for teaching made complex topics easy to grasp. I highly recommend this course to anyone interested in AI and ML!Read moreAbhijit MoneSDEMentorgainI'm Database developer/DBA, Completing the Generative AI course was an insightful experience, deepening my knowledge of Machine Learning. Keerti’s passion for teaching made complex topics easy to grasp. I highly recommend this course to anyone interested in AI and ML!Read moreManika KaushikSenior Software EngineerOptum-United HealthGroupKeerti explains everything in such simple and creative manner, even difficult and huge topics became easy to understand.Frequently asked questionsIs this a Live or Recorded Course?When will the next Live batch be launched?What if I am interested in learning Live only?What are the prerequisites for the course?Is Machine Learning pre-requisite for the course?How many projects will we work on? Can I add these to resume?Is this course for freshers or for experienced people?How will you be able to cover so much in 7 weeks?What languages do we use to build the projects?Can I watch the classes only on the phone without a Laptop?Will you provide the code?Where can I ask you doubts?What language will the course be taught in?Do you have a mobile application?Can I watch the class recordings or go through notes offline?Do you provide certificate for the course?Can I get invoices for reimbursement?I have more questions, how can I reach out to you?EducosysJoin our Discord for updates, upcoming courses and exclusive offers.ConnectFeaturesCoursesBundle CoursesTestimonialsFAQLegalPrivacy PolicyTerms of Services© 2025 ITTI Tech. All rights reserved.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://www.educosys.com/course/genai\"\n",
    ")\n",
    "docs = loader.load()\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7db1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Hands-on Generative AI CourseCoursesBundle CoursesMentorFree ContentTestimonialsFAQLogin Signup Starts on 16th September 2025Hands-on Generative AI CourseLearn, Build, Deploy and Apply Generative AI7 weeks · 3 classes/week · 2 hrs/class + Post-class Doubt SupportClasses on Tue, Wed, Thurs - 9PM ISTAccess all Live BatchesLifetime access of RecordingsAccess Discord CommunityCode availableBuild ProjectsLearn Future-Ready TechEnroll 1Week 1Foundations of Generative AI Introduction to AI Mathematical Foundations for AI Probability, Statistics, and Linear Algebra Basics of Neural Networks Gradient Descent and Optimization Basics Architectures: Feedforward, RNN, and CNN Mini Project - Build a Simple Neural Network Using TensorFlow Mini Project - Train an Autoencoder on the MNIST Dataset2Week 2Deep Generative Models Discriminative and Generative models Generative Adversarial Networks (GANs) Variational Autoencoders (VAEs) Probabilistic Data Generation Using VAEs Four Mini Projects using\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "split = text_splitter.split_documents(docs)\n",
    "print(len(split))\n",
    "print(split[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a856ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0c12ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m      7\u001b[0m     documents\u001b[38;5;241m=\u001b[39msplit,\n\u001b[0;32m      8\u001b[0m     embedding\u001b[38;5;241m=\u001b[39mOpenAIEmbeddings(),\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    885\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    886\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[0;32m    888\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    889\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m    890\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    891\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    892\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    893\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory,\n\u001b[0;32m    894\u001b[0m     client_settings\u001b[38;5;241m=\u001b[39mclient_settings,\n\u001b[0;32m    895\u001b[0m     client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m    896\u001b[0m     collection_metadata\u001b[38;5;241m=\u001b[39mcollection_metadata,\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    898\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:843\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[0;32m    838\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    839\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    840\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    841\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    842\u001b[0m     ):\n\u001b[1;32m--> 843\u001b[0m         chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[0;32m    844\u001b[0m             texts\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[0;32m    845\u001b[0m             metadatas\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    846\u001b[0m             ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    847\u001b[0m         )\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    849\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:591\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    590\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_len_safe_embeddings(\n\u001b[0;32m    592\u001b[0m     texts, engine\u001b[38;5;241m=\u001b[39mengine, chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    593\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:479\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    477\u001b[0m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 479\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtokens[i : i \u001b[38;5;241m+\u001b[39m _chunk_size], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_kwargs\n\u001b[0;32m    481\u001b[0m     )\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    483\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    135\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    136\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    137\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    138\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    139\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    140\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    141\u001b[0m     ),\n\u001b[0;32m    142\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    143\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "os.environ[\"OpenAI_API_KEY\"] = os.getenv(\"openai_api_key\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=split,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72410a32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mget()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "vectorstore._collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d80741a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eef58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7b35e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat_docs\u001b[39m(docs):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Format the output string as needed\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs])\n\u001b[1;32m----> 8\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m ({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: retriever \u001b[38;5;241m|\u001b[39m format_docs,\n\u001b[0;32m      9\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough() \u001b[38;5;241m|\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[0;32m     10\u001b[0m               })\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    # Format the output string as needed\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "rag_chain = ({\"context\": retriever | format_docs,\n",
    "              \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke({\"what are the timings for GenAi courses?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
